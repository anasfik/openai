# ğŸš€ Dart OpenAI

<div align="center">

[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/anasfik/openai)](https://github.com/anasfik/openai)
[![GitHub contributors](https://img.shields.io/github/contributors/anasfik/openai)](https://github.com/anasfik/openai/graphs/contributors)
[![GitHub Repo stars](https://img.shields.io/github/stars/anasfik/openai?style=social)](https://github.com/anasfik/openai)
[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/anasfik/openai/dart.yml?label=tests)](https://github.com/anasfik/openai/actions)
[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/anasfik/openai/release.yml?label=build)](https://github.com/anasfik/openai/actions)
[![GitHub](https://img.shields.io/github/license/anasfik/openai)](https://github.com/anasfik/openai/blob/main/LICENSE)
[![Pub Version](https://img.shields.io/pub/v/dart_openai)](https://pub.dev/packages/dart_openai)
[![Pub Likes](https://img.shields.io/pub/likes/dart_openai)](https://pub.dev/packages/dart_openai)
[![Pub Points](https://img.shields.io/pub/points/dart_openai)](https://pub.dev/packages/dart_openai)
[![Pub Popularity](https://img.shields.io/pub/popularity/dart_openai)](https://pub.dev/packages/dart_openai)

**A comprehensive Dart/Flutter client for OpenAI's powerful AI models**

[Quick Start](#-quick-start) â€¢ [Documentation](#-documentation) â€¢ [Examples](#-examples) â€¢ [API Coverage](#-api-coverage) â€¢ [Contributing](#-contributing)

</div>

---

## âœ¨ Overview

Dart OpenAI is an **unofficial** but comprehensive client package that allows developers to easily integrate OpenAI's state-of-the-art AI models into their Dart/Flutter applications. The package provides simple, intuitive methods for making requests to OpenAI's various APIs, including GPT models, DALL-E image generation, Whisper audio processing, and more.

> **âš ï¸ Note**: This is an **unofficial** package. OpenAI does not have an official Dart library.

### ğŸ¯ Key Features

- ğŸš€ **Easy Integration** - Simple, intuitive API that mirrors OpenAI's documentation
- ğŸ” **Secure Authentication** - One-time setup, use anywhere in your application
- ğŸ“¡ **Streaming Support** - Real-time streaming for completions, chat, and fine-tune events
- ğŸ› ï¸ **Developer Friendly** - Comprehensive error handling and logging
- ğŸ“š **Rich Examples** - Ready-to-use examples for every implemented feature
- ğŸ¨ **Modern UI Support** - Optimized for Flutter applications
- ğŸ”„ **Custom APIs** - Additional custom endpoints for enhanced functionality

---

## ğŸš€ Quick Start

### Installation

Add the package to your `pubspec.yaml`:

```yaml
dependencies:
  dart_openai: ^6.0.0
```

### Basic Setup

```dart
import 'package:dart_openai/dart_openai.dart';

void main() {
  // Set your API key
  OpenAI.apiKey = "your-api-key-here";
  
  // Optional: Set organization ID
  OpenAI.organization = "your-org-id";
  
  // Optional: Configure timeout
  OpenAI.requestsTimeOut = Duration(seconds: 60);
  
  // Optional: Enable logging
  OpenAI.showLogs = true;
  
  runApp(MyApp());
}
```

### Your First API Call

```dart
// Simple chat completion
final chatCompletion = await OpenAI.instance.chat.create(
  model: "gpt-3.5-turbo",
  messages: [
    OpenAIChatCompletionChoiceMessageModel(
      role: OpenAIChatMessageRole.user,
      content: "Hello, how are you?",
    ),
  ],
);

print(chatCompletion.choices.first.message.content);
```

---

## ğŸ“Š API Coverage (2025)

| API feature | Status | Details |
|--------------|--------|----------|
| **ğŸ“‹ [Responses](#-responses)** | âœ… Complete | excluding stream functionality |
| **ğŸ’­ [Conversations](#-conversations)** | âœ… Complete | All |
| **ğŸµ [Audio](#-audio)** | âœ… Complete | All |
| **ğŸ¬ [Videos](#-videos)** | ğŸ—“ï¸ planned | - |
| **ğŸ¨ [Images](#-images)** | âœ… Complete | All |
| **ğŸ¨ [Images Streaaming](#-images-streaaming)** | ğŸ—“ï¸ planned | - |
| **ğŸ“Š [Embeddings](#-embeddings)** | âœ… Complete | All |
| **âš–ï¸ [Evals](#ï¸-evals)** | ğŸ—“ï¸ planned | - |
| **ğŸ”§ [Fine-tuning](#-fine-tuning)** | ğŸ§© 70% Complete | missing newer endpoints |
| **ğŸ“Š [Graders](#-graders)** | âœ… Complete | All |
| **ğŸ“¦ [Batch](#-batch)** | ğŸ—“ï¸ planned | - |
| **ğŸ“ [Files](#-files)** | âœ… Complete | All |
| **ğŸ“¤ [Uploads](#-uploads)** | ğŸ—“ï¸ planned | - |
| **ğŸ¤– [Models](#-models)** | âœ… Complete | All |
| **ğŸ›¡ï¸ [Moderation](#ï¸-moderation)** | âœ… Complete | All|
| **ğŸ—ƒï¸ [Vector Stores](#ï¸-vector-stores)** | ğŸ—“ï¸ planned  | - |
| **ğŸ’¬ ChatKit** | âŒ NOt planned  | Beta feature |
| **ğŸ“¦ [Containers](#-containers)** | ğŸ—“ï¸ planned  | - |
| **ğŸ•› [Real-time](#-real-time)** | ğŸ—“ï¸ planned  | - |
| **ğŸ’¬ [Chat Completions](#-chat-completions)** | âœ… Complete | excluding stream functionality |
| **ğŸ¤– Assistants** | NOt planned | beta feature |
| **ğŸ¤– [Administration](#-administration)** | ğŸ—“ï¸ planned | - |
| **ğŸ“ Completions (Legacy)** | âœ… Complete | Create, Stream, Log probabilities |
| **âœï¸ Edits (Legacy)** | âœ… Complete | Text editing (deprecated by OpenAI) |

---

## ğŸ“š Documentation

### Core APIs

#### ğŸ“‹ Responses

```dart
// Create response
OpenAiResponse response = await OpenAI.instance.responses.create(
  input: "Your input text here",  
  model: "gpt-4",
);

// Get response
OpenAiResponse response = await OpenAI.instance.responses.get(
  responseId: "response-id-here",
  startingAfter: 0, 
);

// Delete response
await OpenAI.instance.responses.delete(
  responseId: "response-id-here",
);

// Update response
OpenAIResponseModel updatedResponse = await OpenAI.instance.responses.update(
  "response-id",
  // ... update parameters
);

// Cancel response
OpenAiResponse response = await OpenAI.instance.responses.cancel(
  responseId: "response-id-here",
);

// list input items
OpenAiResponseInputItemsList response = await OpenAI.instance.responses.listInputItems(
  responseId: "response-id-here",
  limit: 10, 
);

```

#### ğŸ’­ Conversations

```dart
// Create conversation
OpenAIConversation conversation = await OpenAI.instance.conversations.create(
  items: [
    // ...
  ],
  metadata: {
    "key": "value",
    "another_key": "another_value",
  },
);


// Get conversation
OpenAIConversation conversation = await OpenAI.instance.conversations.get(
  conversationId: "conversation-id-here",
);

// Update conversation
OpenAIConversation updatedConversation = await OpenAI.instance.conversations.update(
  conversationId: "conversation-id",
  metadata: {
    "key": "new_value",
  },
);

// Delete conversation
 await OpenAI.instance.conversations.delete(
  conversationId: "conversation-id-here",
);

// list items
OpenAIConversationItemsResponse itemsList = await OpenAI.instance.conversations.listItems(
  conversationId: "conversation-id-here",
  limit: 10, 
);

// Create item
OpenAIConversationItem item = await OpenAI.instance.conversations.createItems(
  conversationId: "conversation-id-here",
  items: [
    // ...
  ],
);

// get item
OpenAIConversationItem item = await OpenAI.instance.conversations.getItem(
  conversationId: "conversation-id-here",
  itemId: "item-id-here",
);

// delete item
await OpenAI.instance.conversations.deleteItem(
  conversationId: "conversation-id-here",
  itemId: "item-id-here",
);
```

#### ğŸµ Audio

```dart
// Create speech
File speechFile = await OpenAI.instance.audio.createSpeech(
  model: "tts-1",
  input: "Text to convert to speech",
  voice: OpenAIAudioVoice.fable,
  responseFormat: OpenAIAudioSpeechResponseFormat.mp3,
  outputDirectory: "/path/to/output/directory",
  outputFileName: "output_speech.mp3",
);


// Transcribe audio
OpenAITranscriptionGeneralModel transcription = await OpenAI.instance.audio.createTranscription(
  model: "whisper-1",
  file: File("path/to/audio.mp3"),
  include: ["logprobs"],
  responseFormat: OpenAIAudioResponseFormat.verbose_json,
  language: "en",
  prompt: "This is a sample prompt to guide transcription",
);
// Handling different transcription response formats
if (transcription is OpenAITranscriptionModel) {
  print(transcription.logprobs);
  print(transcription.text);
  print(transcription.usage);
} else if (transcription is OpenAITranscriptionVerboseModel) {
  // print the transcription.
  print(transcription.text);
  print(transcription.segments?.map((e) => e.end));
}

// Create Translation
final translationText = await OpenAI.instance.audio.createTranslation(
  file: File("path/to/audio.mp3"),
  model: "whisper-1",
  prompt: "use unusual english words",
  responseFormat: OpenAIAudioResponseFormat.json,
);

```

#### ğŸ¬ Videos

// (To be implemented)

#### ğŸ¨ Images

```dart
// Generate image
OpenAIImageModel image = await OpenAI.instance.image.create(
  model: "dall-e-3",
  prompt: "image of a cat in a spaceship",
  responseFormat: OpenAIImageResponseFormat.url,
  size: OpenAIImageSize.size1024,
  quality: OpenAIImageQuality.standard,
  style: OpenAIImageStyle.vivid,
);

// Edit image
OpenAIImageModel imageEdit = await OpenAI.instance.image.edit(
  prompt: 'A fantasy landscape with mountains and a river',
  image: File("path/to/image.png"),
  size: OpenAIImageSize.size1024,
  responseFormat: OpenAIImageResponseFormat.b64Json,
);

// Create variation
List<OpenAIImageModel> imageVariation = await OpenAI.instance.image.variation(
  model: "dall-e-2",
  image: File("path/to/image.png"),
  size: OpenAIImageSize.size512,
  responseFormat: OpenAIImageResponseFormat.url,
);
```

#### ğŸ¨ Images Streaaming

// (To be implemented)

#### ğŸ“Š Embeddings

```dart
OpenAIEmbeddingsModel embedding = await OpenAI.instance.embedding.create(
  model: "text-embedding-ada-002",
  input: "This is a sample text",
);
```

#### âš–ï¸ Evals

// (To be implemented)

#### ğŸ”§ Fine-tuning

// (To be implemented)

#### ğŸ“Š Graders

```dart

// graders
final grader = OpenAIGraders.stringCheckGrader(...);
final grader2 = OpenAIGraders.textSimilarityGrader(...);
final grader3 = OpenAIGraders.scoreModelGrader(...);
final grader4 = OpenAIGraders.labelModelGrader(...);
final grader5 = OpenAIGraders.pythonGrader(...);
final grader6 = OpenAIGraders.multiGrader(...);

// Run grader
final grader = await OpenAI.instance.graders.runGrader(
 grader: grader,
 modelSample: "The model output to be graded", 
);

// Validate Grader
final isValid = OpenAI.instance.graders.validateGrader(
  grader: grader
);
```

#### ğŸ“¦ Batch

// (To be implemented)

#### ğŸ“ Files

```dart
// Upload file
OpenAIFileModel file = await OpenAI.instance.files.upload(
  file: File("path/to/file.jsonl"),
  purpose: OpenAIFilePurpose.fineTune,
);

// List files
List<OpenAIFileModel> files = await OpenAI.instance.files.list(
  limit: 10,
);

// Retrieve file
OpenAIFileModel file = await OpenAI.instance.files.retrieve(
   "file_id" 
);

// Delete file
await OpenAI.instance.files.delete("file-id-here");

// Retrieve file content
final content = await OpenAI.instance.files.retrieveContent(
  "file_id"
);
```

#### ğŸ“¤ Uploads

// (To be implemented)

#### ğŸ¤– Models

```dart
// List all available models
List<OpenAIModelModel> models = await OpenAI.instance.model.list();

// Retrieve specific model
OpenAIModelModel model = await OpenAI.instance.model.retrieve("gpt-3.5-turbo");

// Delete fine-tuned model
bool deleted = await OpenAI.instance.model.delete("fine-tuned-model-id");
```

#### ğŸ›¡ï¸ Moderation

```dart
// Create moderation
OpenAIModerationModel moderation = await OpenAI.instance.moderation.create(
  input: ["Text to classify for moderation"],
  model: "omni-moderation-latest",
);
```

#### ğŸ—ƒï¸ Vector Stores

// (To be implemented)

#### ğŸ“¦ Containers

// (To be implemented)

#### ğŸ•› Real-time

// (To be implemented)

#### ğŸ’¬ Chat Completions

```dart
// Basic chat completion
OpenAIChatCompletionModel chat = await OpenAI.instance.chat.create(
  model: "gpt-3.5-turbo",
  messages: [
    OpenAIChatCompletionChoiceMessageModel(
      role: OpenAIChatMessageRole.user,
      content: "Hello, how can you help me?",
    ),
  ],
  temperature: 0.7,
  maxTokens: 150,
);

// Streaming chat completion
Stream<OpenAIStreamChatCompletionModel> chatStream = OpenAI.instance.chat.createStream(
  model: "gpt-3.5-turbo",
  messages: [
    OpenAIChatCompletionChoiceMessageModel(
      role: OpenAIChatMessageRole.user,
      content: "Tell me a story",
    ),
  ],
);

chatStream.listen((event) {
  print(event.choices.first.delta.content);
});
```

#### ğŸ¤– Administration

// (To be implemented)

---


## ğŸ”§ Configuration

### Environment Variables

```dart
// Using envied package
@Envied(path: ".env")
abstract class Env {
  @EnviedField(varName: 'OPEN_AI_API_KEY')
  static const apiKey = _Env.apiKey;
}

void main() {
  OpenAI.apiKey = Env.apiKey;
  runApp(MyApp());
}
```

### Custom Configuration

```dart
void main() {
  // Set API key
  OpenAI.apiKey = "your-api-key";
  
  // Set organization (optional)
  OpenAI.organization = "your-org-id";
  
  // Set custom base URL (optional)
  OpenAI.baseUrl = "https://api.openai.com/v1";
  
  // Set request timeout (optional)
  OpenAI.requestsTimeOut = Duration(seconds: 60);
  
  // Enable logging (optional)
  OpenAI.showLogs = true;
  OpenAI.showResponsesLogs = true;
  
  runApp(MyApp());
}
```

---

## ğŸš¨ Error Handling

```dart
try {
  final chat = await OpenAI.instance.chat.create(
    model: "gpt-3.5-turbo",
    messages: [
      OpenAIChatCompletionChoiceMessageModel(
        role: OpenAIChatMessageRole.user,
        content: "Hello",
      ),
    ],
  );
} on RequestFailedException catch (e) {
  print("Request failed: ${e.message}");
  print("Status code: ${e.statusCode}");
} on MissingApiKeyException catch (e) {
  print("API key not set: ${e.message}");
} on UnexpectedException catch (e) {
  print("Unexpected error: ${e.message}");
}
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

### ğŸ› Bug Reports

- Use [GitHub Issues](https://github.com/anasfik/openai/issues) to report bugs
- Include reproduction steps and environment details

### ğŸ’¡ Feature Requests

- Suggest new features via [GitHub Issues](https://github.com/anasfik/openai/issues)
- Check existing issues before creating new ones

### ğŸ”§ Code Contributions

- Fork the repository
- Create a feature branch
- Make your changes
- Add tests if applicable
- Submit a pull request

### ğŸ“š Documentation

- Help improve documentation
- Add examples for missing features
- Fix typos and improve clarity

### ğŸ’° Sponsoring

- [Sponsor the project](https://github.com/sponsors/anasfik)
- Help maintain and improve the package

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **OpenAI** for providing the amazing AI models and APIs
- **Contributors** who help maintain and improve this package
- **Sponsors** who support the project financially
- **Community** for feedback and suggestions

---

## ğŸ“ Support

- ğŸ“– [Full Documentation](https://pub.dev/documentation/dart_openai/latest/)
- ğŸ› [Report Issues](https://github.com/anasfik/openai/issues)
- ğŸ’¬ [Discussions](https://github.com/anasfik/openai/discussions)
- ğŸ“§ [Contact](https://github.com/anasfik)

---

<div align="center">


**Made with â¤ï¸ by the Dart OpenAI community**

[â­ Star this repo](https://github.com/anasfik/openai) â€¢ [ğŸ› Report Bug](https://github.com/anasfik/openai/issues) â€¢ [ğŸ’¡ Request Feature](https://github.com/anasfik/openai/issues) â€¢ [ğŸ“– Documentation](https://pub.dev/documentation/dart_openai/latest/)

</div>
